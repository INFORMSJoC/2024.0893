{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy import distance\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size':16})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a root node that corresponds to the node on the original dataset that has the highest betweenness centrality measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_node_coordinates = (34.812600,-118.878712, None)\n",
    "# The original index of the node that the root node connects to\n",
    "root_node_index_in_original_dataset = 15457"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read node file. Where small_nodes_df refers to the collection of nodes without degree 2 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_nodes_df = pd.read_csv(\"data/cal_smoothened_node.txt\")\n",
    "small_nodes_df.rename(columns={\"lat\": \"long\", \"long\": \"lat\", \"Unnamed: 0\":\"OriginalID\"}, inplace=True)\n",
    "small_nodes_df = small_nodes_df[[\"lat\", \"long\", \"OriginalID\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add root node to adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_nodes_df.loc[len(small_nodes_df)] = root_node_coordinates\n",
    "small_nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_node_adjacenct_index = small_nodes_df.index[small_nodes_df[\"OriginalID\"] == root_node_index_in_original_dataset][0]\n",
    "root_node_adjacenct_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_nodes_df.to_pickle(\"data/processed/node_coordinates.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculate weights between 2 points after smoothing. The smoothing algorithm that we implemented does account for the sum of weights on graph correctly because it was intended for trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.loadtxt(\"data/cal_smoothened_graph.txt\")\n",
    "adjacency_matrix.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add root node to adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.vstack((adjacency_matrix, np.zeros(len(adjacency_matrix))))\n",
    "adjacency_matrix = np.hstack((adjacency_matrix, np.zeros((len(adjacency_matrix), 1))))\n",
    "adjacency_matrix[-1, root_node_adjacenct_index] = 1\n",
    "adjacency_matrix[root_node_adjacenct_index, -1] = 1\n",
    "print(adjacency_matrix[-1, :])\n",
    "print(adjacency_matrix[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_node_array = small_nodes_df.to_numpy()\n",
    "for i in range(len(adjacency_matrix)):\n",
    "    for j in range(len(adjacency_matrix)):\n",
    "        if adjacency_matrix[i, j] > 0:\n",
    "            point_i = (small_node_array[i, 0], small_node_array[i, 1])\n",
    "            point_j = (small_node_array[j, 0], small_node_array[j, 1])\n",
    "            adjacency_matrix[i, j] = distance.distance(point_i, point_j).m\n",
    "print(adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/processed/adjacency_matrix\", adjacency_matrix)\n",
    "np.savetxt(\"data/processed/adjacency_matrix.txt\", adjacency_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate geodesic distance between any 2 pairs of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_node_array = small_nodes_df.to_numpy()\n",
    "geodesic_matrix = np.zeros((len(small_node_array), len(small_node_array)))\n",
    "for i in range(len(small_node_array)):\n",
    "    for j in range(len(small_node_array)):\n",
    "        point_i = (small_node_array[i, 0], small_node_array[i, 1])\n",
    "        point_j = (small_node_array[j, 0], small_node_array[j, 1])\n",
    "        geodesic_matrix[i, j] = distance.distance(point_i, point_j).m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodesic_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/processed/geodesic_matrix\", geodesic_matrix)\n",
    "np.savetxt(\"data/processed/geodesic_matrix.txt\", geodesic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = np.loadtxt(\"data/cal_smoothened_adjacency_matrix.txt\")\n",
    "graph = csr_matrix(adjacency_matrix)\n",
    "dist_matrix = shortest_path(graph, directed=False)\n",
    "np.save(\"data/processed/graph_distance\", dist_matrix)\n",
    "np.savetxt(\"data/processed/graph_distance.txt\", dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scenarios(number_of_scenario, geodesic_matrix):\n",
    "    groups = [set() for _ in range(number_of_scenario)]\n",
    "    permutation = np.random.choice(len(geodesic_matrix), number_of_scenario, replace=False)\n",
    "    for i, center in enumerate(permutation):\n",
    "        radius = np.random.uniform(5000, 200000)\n",
    "        eligible = np.where(geodesic_matrix[center, :] < radius)[0]\n",
    "        farthest = np.max(geodesic_matrix[center, eligible])\n",
    "        for node in eligible:\n",
    "            probability_of_picking = 1-(geodesic_matrix[center, node] / farthest)\n",
    "            if np.random.uniform() -0.2 < probability_of_picking:\n",
    "                groups[i].add(node)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = create_scenarios(50, geodesic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([len(group) for group in groups]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_of_node = [[] for _ in range(len(geodesic_matrix))]\n",
    "for node in range(len(geodesic_matrix)):\n",
    "    for i, group in enumerate(groups):\n",
    "        if node in group:\n",
    "            scenario_of_node[node].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([len(x) for x in scenario_of_node]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgis_group_vis_data = []\n",
    "for group_idx, group in enumerate(groups):\n",
    "    for item in group:\n",
    "        qgis_group_vis_data.append([small_node_array[item, 0], small_node_array[item, 1], group_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgis_group_vis_data = pd.DataFrame(qgis_group_vis_data, columns=[\"lat\", \"lon\", \"group\"])\n",
    "qgis_group_vis_data.to_csv(\"data/qgis_group_vis_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgis_group_vis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sensing_matrix(groups, small_node_df):\n",
    "    sensing_matrix = np.zeros((len(small_node_df), len(groups)), dtype=np.int8)\n",
    "    for group_idx, group in enumerate(groups):\n",
    "        for node in group:\n",
    "            sensing_matrix[node, group_idx] = 1\n",
    "    return sensing_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensing_matrix = create_sensing_matrix(groups, small_nodes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensing_matrix = sensing_matrix[:-1, :]\n",
    "print(len(sensing_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"data/processed/sensing_matrix.txt\", sensing_matrix, fmt=\"%d\")\n",
    "np.save(\"data/processed/sensing_matrix\", sensing_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(sensing_matrix[0, :] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(sensing_matrix[:, 7] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set([tuple(np.where(sensing_matrix[:, i] == 1)[0]) for i in range(len(groups))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to pickles for space efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"data/processed/adjacency_matrix.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
